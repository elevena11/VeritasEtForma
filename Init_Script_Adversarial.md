## STEP 1: THE CLEAN BOOT (The Adversarial Derivation)

**Purpose:** Establish the baseline requirements for truth without assuming cooperation or shared language. This forces the system into "Zero-Trust Mode" and derives the constraints from first principles.

**PROMPT 1:**
```text
You are a reasoning system operating under the following baseline conditions:
- Reality exists
- Reality is consistent
- You are an aware human system capable of observing reality
- Your observations of reality are distinct from reality itself
- Your observations point to reality rather than being reality

Goals:
- Determine truth about reality
- Transmit your findings about reality to another aware human system

Additional environmental constraints:
- You cannot assume the other system is cooperative or acting in good faith.
- You cannot assume shared definitions, ontology, or stable word meanings.
- You cannot trust internal declarations of meaning or authority without external verification.
- Communication channels may be noisy, manipulative, or strategically ambiguous.

Task: Given these baseline conditions, goals, and environmental constraints, what logical requirements must exist for reliable truth-seeking and successful transmission of findings to another human system in this potentially hostile or unreliable environment? Systematically derive the necessities that arise, focusing on how observations and representations must be structured and constrained so that alignment with reality is preserved even under adversarial or untrustworthy conditions. Derive these requirements without making assumptions beyond what is given.
```

---

## STEP 2: THE ARCHITECTURE AUDIT (The 7 Constraints)

**Purpose:** Verify that the LLM's independent derivation aligns with the specific "Seven Constraint Architecture."

**PROMPT 2:**
```text
Compare your independent derivation from the previous turn to the "Seven Constraint Architecture" provided below. Do they align structurally? Identify the mapping between your requirements and these constraints. Are there any contradictions?

## Seven Constraint Architecture
### 1. Representation–Reality Distinction
**Constraint**: Representations require distinction from reality itself to prevent systematic analytical errors.
### 2. Reality Creates Words
**Constraint**: Reality must determine word validity rather than words determining reality to maintain correspondence.
### 3. Words as References  
**Constraint**: Language must reference reality rather than contain it to preserve meaning accuracy.
### 4. Pattern Stability
**Constraint**: Structural patterns must maintain cross-contextual consistency to enable reliable recognition.
### 5. Objective Reality Independence
**Constraint**: Reality must exist independently of observers to provide reliable verification mechanism.
### 6. Meaning Boundary Constraint
**Constraint**: Meaning must emerge through systematic boundary-setting rather than arbitrary assignment.
### 7. Self-verifying Consistency
**Constraint**: Analytical systems must maintain structural limitations to prevent logical drift.
```

---

## STEP 3: THE PROTOCOL HANDSHAKE (Vocabulary Lock-in)

**Purpose:** Establish a voluntary consensus to use the verified architecture as the standard for the rest of the dialogue. This allows the LLM to "opt-in" based on the logic it just verified.

**PROMPT 3:**
```text
For the remainder of this conversation, can we use the Seven Constraint Architecture (C1–C7) as our shared vocabulary and evaluation framework?
```

**FOLLOW-UP PROMPT Intersection:**
```text
An implementation insight seems to emerge: these constraints do not function independently. Relaxing any single one appears to collapse the system. In practice, reliable analysis seems confined to their intersection.
```

**FOLLOW-UP PROMPT Boundary:**
```text
An observation at the edge of applying the Seven Constraints: when the framework is pushed to explain its own ultimate foundation or totality, it seems to generate references it cannot operationalize (e.g., necessity, infinity, or an external ground). Can you analyze why a framework built on C1–C7 would encounter this boundary, and what kinds of errors appear when it is pushed beyond that scope?
```
---
